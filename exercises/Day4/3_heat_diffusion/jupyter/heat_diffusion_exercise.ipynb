{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8945d7f9-1bff-4240-afa3-02d40381db9f",
   "metadata": {},
   "source": [
    "## Exercise: Heat diffusion on CPUs and GPU\n",
    "\n",
    "**NOTE: This notebook should be run with multiple Julia threads!**\n",
    "\n",
    "#### Exercise objective\n",
    "1) Understand how to (step-by-step) transform a vectorized numerical code into a faster, multithreaded loop-variant and, eventually, into a CUDA kernel running on a GPU.\n",
    "2) Compare the performance of different variants of the code (vectorized CPU, vectorized GPU, multithreaded loop CPU, CUDA kernel GPU).\n",
    "\n",
    "#### The problem\n",
    "We consider the heat equation, a partial differential equation (PDE) describing the diffusion of heat over time. The PDE reads\n",
    "\n",
    "$$ \\dfrac{\\partial T}{\\partial t} = \\alpha \\left( \\dfrac{\\partial^2 T}{\\partial x^2} + \\dfrac{\\partial^2 T}{\\partial y^2} \\right), $$\n",
    "\n",
    "where the temperature $T = T(x,y,t)$ is a function of space ($x,y$) and time ($t$) and $\\alpha$ is a scaling coefficient. Specifically, we'll consider a simple two-dimensional square geometry. As the initial condition - the starting distribution of temperature across the geometry - we choose a [\"Gaussian\"](https://en.wikipedia.org/wiki/Gaussian_function#:~:text=In%20mathematics%2C%20a%20Gaussian%20function,characteristic%20symmetric%20%22bell%20curve%22%20shape) positioned in the center. In summary, the starting configuration looks like this:\n",
    "\n",
    "![](../../../other/imgs/heat_diffusion_initial_condition.png)\n",
    "\n",
    "#### Numerical approach\n",
    "1) We discretize space (`dx`, `dy`) and time (`dt`) and evaluate everything on a grid.\n",
    "2) We use the basic [finite difference method](https://en.wikipedia.org/wiki/Finite_difference_method) to compute derivatives on the grid, e.g.\n",
    "$$\n",
    "\\dfrac{\\partial T}{\\partial x}(x_i) \\approx \\dfrac{f(x_{i+1}) - f(x_i)}{\\Delta x} \n",
    "$$\n",
    "3) We use a two-step process:\n",
    "    a) Compute the first-order spatial derivates.\n",
    "    b) Then, update the temperature field (time integration).\n",
    "$$ \n",
    "\\begin{align}\n",
    "\\partial x &= \\dfrac{\\Delta T}{\\Delta x} \\\\\n",
    "\\partial y &= \\dfrac{\\Delta T}{\\Delta y} \\\\\n",
    "\\Delta T &= \\alpha\\Delta t \\left( \\dfrac{\\Delta (\\partial x)}{\\Delta x} + \\dfrac{(\\Delta \\partial y)}{\\Delta y} \\right)\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "#### Performance metric\n",
    "Note that the derivatives give our numerical solver the character of a [stencil](https://en.wikipedia.org/wiki/Iterative_Stencil_Loops). Stencils are typically memory bound, that is, data transfer is dominating over FLOPs and consequently performance is limited by the rate at which memory is transferred between memory and the arithmetic units. For this reason we will measure the performance in terms of an [effective memory throughput metric](https://github.com/omlins/ParallelStencil.jl#performance-metric)\n",
    "\n",
    "$$T_\\textrm{eff} = \\dfrac{2 n_x n_y \\delta}{t_{\\textrm{it}}} \\cdot 10^{-9} \\quad [\\textrm{GB/s}]$$\n",
    "\n",
    "where $t_{\\textrm{it}}$ is the time per iteration and $\\delta$ is the arithmetic precision (8 or 4 bytes for `Float64` or `Float32` respectively)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6be193a0",
   "metadata": {},
   "source": [
    "## CPU - Vectorized\n",
    "\n",
    "Below you find a code snippet for the integration of the heat equation. \n",
    "\n",
    "**Task 1**\n",
    "\n",
    "1) Implement the missing piece, that is, the update of the temperature field.\n",
    "\n",
    "**Remarks**\n",
    "\n",
    "* Finite difference method: You can use `diff(A, dims=1) ./ dx` to compute the partial derivative of a field `A` in the x-direction (`dims=2` corresponds to y-direction).\n",
    "* Don't update the temperature `T` at the boundary of the 2D square geometry. That is, only update the inner part `T[2:(end - 1), 2:(end - 1)]`.\n",
    "* When implemented correctly, you should get this animation:\n",
    "\n",
    "![](../../../other/imgs/heat_diffusion_animation.gif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c08ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "using Plots\n",
    "using Printf\n",
    "\n",
    "@views function heat_2D_animation()\n",
    "    # physical parameters\n",
    "    lx, ly = 10.0, 10.0 # spacial dimension\n",
    "    α = 1.0 # coefficient\n",
    "    \n",
    "    # spatial grid\n",
    "    nx, ny = 128, 128\n",
    "    dx, dy = lx/nx, ly/ny\n",
    "    xc = range(start=dx/2, stop=lx-dx/2, length=nx)\n",
    "    yc = range(start=dy/2, stop=ly-dy/2, length=ny)\n",
    "\n",
    "    # time discretization\n",
    "    dt = min(dx^2,dy^2)/α/4.1\n",
    "    nt = 400 # timestepts\n",
    "    \n",
    "    # initial condition - gaussian sitting at the center\n",
    "    T = exp.(.-(xc.-lx./2.0).^2 .-(yc.-ly./2.0)'.^2)\n",
    "\n",
    "    # preallocation\n",
    "    ∂x = zeros(nx-1,ny-2)\n",
    "    ∂y = zeros(nx-2,ny-1)\n",
    "    \n",
    "    # time loop\n",
    "    @gif for it = 1:nt \n",
    "        # -------- stencil kernel --------\n",
    "        # first order derivatives\n",
    "        ∂x .= diff(T[:, 2:(end - 1)], dims = 1) ./ dx\n",
    "        ∂y .= diff(T[2:(end - 1), :], dims = 2) ./ dy\n",
    "\n",
    "        #\n",
    "        # !!!! Task 1 TODO: update T\n",
    "        #\n",
    "        \n",
    "        # --------------------------------\n",
    "\n",
    "        # plotting\n",
    "        heatmap(xc, yc, T', xlabel=\"x\", ylabel=\"y\", title=\"Heat Diffusion, i=$it\", clims=(0.,1.))\n",
    "    end every 5\n",
    "end\n",
    "\n",
    "heat_2D_animation()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "efc52f71",
   "metadata": {},
   "source": [
    "### Performance (without animation)\n",
    "Let's get rid of the animation and measure the performance of our implementation. Please copy your solution for Task 1 above and paste it at the marked position."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af54dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "using Printf\n",
    "\n",
    "@views function heat_2D(; ngrid=1024)\n",
    "    # physical parameters\n",
    "    lx, ly = 10.0, 10.0 # spacial dimension\n",
    "    α = 1.0 # coefficient\n",
    "\n",
    "    # spatial grid\n",
    "    nx, ny = ngrid, ngrid\n",
    "    dx, dy = lx / nx, ly / ny\n",
    "    xc = range(start = dx / 2, stop = lx - dx / 2, length = nx)\n",
    "    yc = range(start = dy / 2, stop = ly - dy / 2, length = ny)\n",
    "\n",
    "    # time discretization\n",
    "    dt = min(dx^2, dy^2) / α / 4.1\n",
    "    nt = 400 # timestepts\n",
    "\n",
    "    # initial condition - gaussian sitting at the center\n",
    "    T = exp.(.-(xc .- lx ./ 2.0) .^ 2 .- (yc .- ly ./ 2.0)' .^ 2)\n",
    "\n",
    "    # preallocation\n",
    "    ∂x = zeros(nx - 1, ny - 2)\n",
    "    ∂y = zeros(nx - 2, ny - 1)\n",
    "\n",
    "    # time loop\n",
    "    t0 = Base.time()\n",
    "    for it in 1:nt\n",
    "        # time measurement (skip first 10 iterations)\n",
    "        if it == 11\n",
    "            t0 = Base.time()\n",
    "        end\n",
    "\n",
    "        # -------- stencil kernel --------\n",
    "        # first order derivatives\n",
    "        ∂x .= diff(T[:, 2:(end - 1)], dims = 1) ./ dx\n",
    "        ∂y .= diff(T[2:(end - 1), :], dims = 2) ./ dy\n",
    "        # update T\n",
    "        \n",
    "        #\n",
    "        # !!!! TODO: update T (just copy your solution from Task 1 here as well)\n",
    "        #\n",
    "\n",
    "        # --------------------------------\n",
    "    end\n",
    "    time_s = Base.time() - t0\n",
    "    T_eff = round((2 * nx * ny * sizeof(eltype(T)) / (time_s / (nt - 10))) * 1e-9, sigdigits = 2)\n",
    "    @printf(\"T_eff = %1.2f GB/s, Time = %1.4e s \\n\", T_eff, time_s)\n",
    "    return nothing\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0944221b",
   "metadata": {},
   "outputs": [],
   "source": [
    "println(\"CPU - Vectorized:\")\n",
    "heat_2D()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "eb4fe655",
   "metadata": {},
   "source": [
    "## CPU - Loop Multithreaded\n",
    "To multithread our stencil computation - and to later transform it into a CUDA kernel - we need a version of our numerical solver in terms of loops rather than broadcasting (vectorized). Below you find a corresponding code snippet where we've outsourced the first-order derivation computation into a function `compute_first_order_loop_mt!` and the temperature field update into `update_T_loop_mt!`. Like above, the first-order derivative computation is already implemented. Check it out to understand what has changed.\n",
    "\n",
    "**Task 2**\n",
    "\n",
    "1) Implement the missing piece, that is, the update of the temperature field via a multithreaded loop.\n",
    "\n",
    "**Remarks**\n",
    "\n",
    "* To respect column-major order (memory layout), the y-loop should be the outer loop and the x-loop the inner one.\n",
    "* Use `@threads :static for ...` to parallelize the outer y-loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d484fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "using ThreadPinning\n",
    "using Printf\n",
    "\n",
    "if Threads.nthreads() == 1\n",
    "    error(\"This part is supposed to be run with multiple Julia threads.\")\n",
    "end\n",
    "pinthreads(:numa)\n",
    "\n",
    "function compute_first_order_loop_mt!(∂x, ∂y, T, dx, dy, nx, ny)\n",
    "    Threads.@threads :static for iy in 2:(ny - 1)\n",
    "        for ix in 1:(nx - 1)\n",
    "            ∂x[ix, iy - 1] = (T[ix + 1, iy] - T[ix, iy]) / dx\n",
    "        end\n",
    "    end\n",
    "    Threads.@threads :static for iy in 1:(ny - 1)\n",
    "        for ix in 2:(nx - 1)\n",
    "            ∂y[ix - 1, iy] = (T[ix, iy + 1] - T[ix, iy]) / dy\n",
    "        end\n",
    "    end\n",
    "    return nothing\n",
    "end\n",
    "\n",
    "function update_T_loop_mt!(T, ∂x, ∂y, dt, α, dx, dy, nx, ny)\n",
    "    \n",
    "    #\n",
    "    # Task 2 TODO: Implement update of T via multithreaded loops.\n",
    "    #              See `compute_first_order_loop_mt!` for inspiration.\n",
    "    #\n",
    "\n",
    "    return nothing\n",
    "end\n",
    "\n",
    "@views function heat_2D_loop_multithreaded(; ngrid=1024)\n",
    "    # physical parameters\n",
    "    lx, ly = 10.0, 10.0 # spacial dimension\n",
    "    α = 1.0 # coefficient\n",
    "\n",
    "    # spatial grid\n",
    "    nx, ny = ngrid, ngrid\n",
    "    dx, dy = lx / nx, ly / ny\n",
    "    xc = range(start = dx / 2, stop = lx - dx / 2, length = nx)\n",
    "    yc = range(start = dy / 2, stop = ly - dy / 2, length = ny)\n",
    "\n",
    "    # time discretization\n",
    "    dt = min(dx^2, dy^2) / α / 4.1\n",
    "    nt = 400 # timestepts\n",
    "\n",
    "    # initial condition - gaussian sitting at the center\n",
    "    T = exp.(.-(xc .- lx ./ 2.0) .^ 2 .- (yc .- ly ./ 2.0)' .^ 2)\n",
    "\n",
    "    # preallocation\n",
    "    ∂x = zeros(nx - 1, ny - 2)\n",
    "    ∂y = zeros(nx - 2, ny - 1)\n",
    "\n",
    "    # time loop\n",
    "    t0 = Base.time()\n",
    "    for it in 1:nt\n",
    "        # time measurement (skip first 10 iterations)\n",
    "        if it == 11\n",
    "            t0 = Base.time()\n",
    "        end\n",
    "\n",
    "        # -------- stencil kernel --------\n",
    "        # first order derivatives\n",
    "        compute_first_order_loop_mt!(∂x, ∂y, T, dx, dy, nx, ny)\n",
    "        # update T\n",
    "        update_T_loop_mt!(T, ∂x, ∂y, dt, α, dx, dy, nx, ny)\n",
    "        # --------------------------------\n",
    "    end\n",
    "    time_s = Base.time() - t0\n",
    "    T_eff = round((2 * nx * ny * sizeof(eltype(T)) / (time_s / (nt - 10))) * 1e-9, sigdigits = 2)\n",
    "    @printf(\"T_eff = %1.2f GB/s, Time = %1.4e s \\n\", T_eff, time_s)\n",
    "    return nothing\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b23bac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "println(\"CPU - Loop Multithreaded:\")\n",
    "heat_2D_loop_multithreaded()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cdf9e1ff",
   "metadata": {},
   "source": [
    "## GPU - Vectorized\n",
    "The simplest way to make our numerical code run on the GPU is to use array abstractions, that is, `CuArray`s instead of the regular `Array`s. Below you find precisely the same code snippet as for Task 1 (CPU vectorized).\n",
    "\n",
    "**Task 3**\n",
    "\n",
    "1) Initialize the arrays `T`, `∂x`, and `∂y` on the GPU by making the `CuArray`s. Leave the rest of the code the same.\n",
    "2) Do you notice a change in performance?\n",
    "\n",
    "**Remarks**\n",
    "\n",
    "* Since the initialization of the arrays isn't part of our time measurement you can either initialize the arrays directly on the GPU or move them there before the computation. Up to you :)\n",
    "* **Important:** For a fair comparison in terms of `T_eff` (effective memory bandwidth), we need to use `CuArray{Float64}` rather than just `CuArray`, which defaults to `CuArray{Float32}`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd74620",
   "metadata": {},
   "outputs": [],
   "source": [
    "using CUDA\n",
    "using Printf\n",
    "\n",
    "@views function heat_2D_gpu(; ngrid=1024)\n",
    "    # physical parameters\n",
    "    lx, ly = 10.0, 10.0 # spacial dimension\n",
    "    α = 1.0 # coefficient\n",
    "\n",
    "    # spatial grid\n",
    "    nx, ny = ngrid, ngrid\n",
    "    dx, dy = lx / nx, ly / ny\n",
    "    xc = range(start = dx / 2, stop = lx - dx / 2, length = nx)\n",
    "    yc = range(start = dy / 2, stop = ly - dy / 2, length = ny)\n",
    "\n",
    "    # time discretization\n",
    "    dt = min(dx^2, dy^2) / α / 4.1\n",
    "    nt = 400 # timestepts\n",
    "\n",
    "    # initial condition - gaussian sitting at the center\n",
    "    #\n",
    "    # Task 3 TODO: Put T on the GPU by making it a `CuArray`\n",
    "    #\n",
    "    T = exp.(.-(xc .- lx ./ 2.0) .^ 2 .- (yc .- ly ./ 2.0)' .^ 2)\n",
    "\n",
    "    # preallocation\n",
    "    #\n",
    "    # Task 3 TODO: Put ∂x and ∂y on the GPU by making it a `CuArray`\n",
    "    #\n",
    "    ∂x = zeros(nx - 1, ny - 2)\n",
    "    ∂y = zeros(nx - 2, ny - 1)\n",
    "\n",
    "    # time loop\n",
    "    t0 = Base.time()\n",
    "    for it in 1:nt\n",
    "        # time measurement (skip first 10 iterations)\n",
    "        if it == 11\n",
    "            t0 = Base.time()\n",
    "        end\n",
    "\n",
    "        # -------- stencil kernel --------\n",
    "        # first order derivatives\n",
    "        ∂x .= diff(T[:, 2:(end - 1)], dims = 1) ./ dx\n",
    "        ∂y .= diff(T[2:(end - 1), :], dims = 2) ./ dy\n",
    "        # update T\n",
    "        T[2:(end - 1), 2:(end - 1)] .= T[2:(end - 1), 2:(end - 1)] .+\n",
    "                                       dt .* α .* (diff(∂x, dims = 1) ./ dx .+\n",
    "                                        diff(∂y, dims = 2) ./ dy)\n",
    "        # --------------------------------\n",
    "    end\n",
    "    time_s = Base.time() - t0\n",
    "    T_eff = round((2 * nx * ny * sizeof(eltype(T)) / (time_s / (nt - 10))) * 1e-9, sigdigits = 2)\n",
    "    @printf(\"T_eff = %1.2f GB/s, Time = %1.4e s \\n\", T_eff, time_s)\n",
    "    return\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ebef27",
   "metadata": {},
   "outputs": [],
   "source": [
    "println(\"GPU - Vectorized:\")\n",
    "heat_2D_gpu()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ca02d41e",
   "metadata": {},
   "source": [
    "## GPU - CUDA Kernels\n",
    "Finally, we want to transform our loop implementations of `compute_first_order_loop_mt!` and `update_T_mt!` above into CUDA kernels. To that end, we simply replace the (multithreaded) `for`-loops by `if`-conditions that make sure that the indices stay within the bounds of the arrays. When the kernel is later spawned with `@cuda`, different GPU-threads will run our kernel function with different indices and thus realize the full update.\n",
    "\n",
    "**Task 4**\n",
    "\n",
    "1) Implement the update of the temperature field as a CUDA kernel.\n",
    "2) At the marked position, spawn the `update_T_gpu!` kernel with `@cuda` using `cublocks`-many blocks and `cuthreads`-many threads.\n",
    "\n",
    "**Remarks**\n",
    "\n",
    "* You may take `compute_first_order_gpu!` as inspiration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce0b496",
   "metadata": {},
   "outputs": [],
   "source": [
    "using CUDA\n",
    "using Printf\n",
    "\n",
    "function compute_first_order_gpu!(∂x, ∂y, T, dx, dy, nx, ny)\n",
    "    ix = (blockIdx().x - 1) * blockDim().x + threadIdx().x # thread ID, dimension x\n",
    "    iy = (blockIdx().y - 1) * blockDim().y + threadIdx().y # thread ID, dimension y\n",
    "\n",
    "    if ix <= nx - 1\n",
    "        if 2 <= iy <= ny - 1\n",
    "            ∂x[ix, iy - 1] = (T[ix + 1, iy] - T[ix, iy]) / dx\n",
    "        end\n",
    "    end\n",
    "    if 2 <= ix <= nx - 1\n",
    "        if iy <= ny - 1\n",
    "            ∂y[ix - 1, iy] = (T[ix, iy + 1] - T[ix, iy]) / dy\n",
    "        end\n",
    "    end\n",
    "    return nothing\n",
    "end\n",
    "\n",
    "function update_T_gpu!(T, ∂x, ∂y, dt, α, dx, dy, nx, ny)\n",
    "    \n",
    "    #\n",
    "    # Task 4 TODO: Implement the temperature update as a CUDA kernel.\n",
    "    #              See `compute_first_order_gpu!` above for inspiration.\n",
    "    #\n",
    "\n",
    "    return nothing\n",
    "end\n",
    "\n",
    "@views function heat_2D_gpu_kernels(; ngrid=1024)\n",
    "    # physical parameters\n",
    "    lx, ly = 10.0, 10.0 # spacial dimension\n",
    "    α = 1.0 # coefficient\n",
    "\n",
    "    # spatial grid\n",
    "    blockx, blocky = 32, 32\n",
    "    gridx, gridy = ngrid ÷ 32, ngrid ÷ 32\n",
    "    cuthreads = (blockx, blocky, 1)\n",
    "    cublocks = (gridx, gridy, 1)\n",
    "    nx, ny = blockx * gridx, blocky * gridy\n",
    "    dx, dy = lx / nx, ly / ny\n",
    "    xc = range(start = dx / 2, stop = lx - dx / 2, length = nx)\n",
    "    yc = range(start = dy / 2, stop = ly - dy / 2, length = ny)\n",
    "\n",
    "    # time discretization\n",
    "    dt = min(dx^2, dy^2) / α / 4.1\n",
    "    nt = 400 # timestepts\n",
    "\n",
    "    # initial condition - gaussian sitting at the center\n",
    "    T = CuArray{Float64}(exp.(.-(xc .- lx ./ 2.0) .^ 2 .- (yc .- ly ./ 2.0)' .^ 2))\n",
    "\n",
    "    # preallocation\n",
    "    ∂x = CUDA.zeros(Float64, nx - 1, ny - 2)\n",
    "    ∂y = CUDA.zeros(Float64, nx - 2, ny - 1)\n",
    "\n",
    "    # time loop\n",
    "    t0 = Base.time()\n",
    "    for it in 1:nt\n",
    "        # time measurement (skip first 10 iterations)\n",
    "        if it == 11\n",
    "            t0 = Base.time()\n",
    "        end\n",
    "\n",
    "        # -------- stencil kernel --------\n",
    "        # first order derivatives\n",
    "        CUDA.@sync @cuda blocks=cublocks threads=cuthreads compute_first_order_gpu!(∂x, ∂y,\n",
    "                                                                                    T, dx,\n",
    "                                                                                    dy, nx,\n",
    "                                                                                    ny)\n",
    "\n",
    "        # update T\n",
    "        \n",
    "        #\n",
    "        # Task 4 TODO: Spawn the `update_T_gpu!` kernel with `@cuda`.\n",
    "        #\n",
    "        \n",
    "        # --------------------------------\n",
    "    end\n",
    "    time_s = Base.time() - t0\n",
    "    T_eff = round((2 * nx * ny * sizeof(eltype(T)) / (time_s / (nt - 10))) * 1e-9, sigdigits = 2)\n",
    "    @printf(\"T_eff = %1.2f GB/s, Time = %1.4e s \\n\", T_eff, time_s)\n",
    "    return\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f29459",
   "metadata": {},
   "outputs": [],
   "source": [
    "println(\"GPU - CUDA Kernels:\")\n",
    "heat_2D_gpu_kernels()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "71fbc5e2",
   "metadata": {},
   "source": [
    "## Performance Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da6061bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "println(\"CPU - Vectorized:\")\n",
    "heat_2D()\n",
    "\n",
    "println(\"CPU - Loop Multithreaded:\")\n",
    "heat_2D_loop_multithreaded()\n",
    "\n",
    "println(\"GPU - Vectorized:\")\n",
    "heat_2D_gpu()\n",
    "\n",
    "println(\"GPU - CUDA Kernels:\")\n",
    "heat_2D_gpu_kernels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d607bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.9.0-rc2",
   "language": "julia",
   "name": "julia-1.9"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.9.0-rc2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
