{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "42d3d18f",
   "metadata": {},
   "source": [
    "# Specialization\n",
    "\n",
    "To be fast, Julia needs to **specialize** code, that is compile specific native versions of the code utilizing the type information. **The better the specialization the faster the code!**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6add0fc5",
   "metadata": {
    "tags": []
   },
   "source": [
    "## \"Just ahead of time\" compilation\n",
    "\n",
    "* Julia **specializes on the types of function arguments** and \n",
    "* compiles efficient machine code **when a function is called for the first time** (with these input argument types).\n",
    "\n",
    "If the same function is called again with the same input argument types, the already existing machine code is reused.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc2352e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "func(x,y) = 2x + y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa5f7c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [1.2, 3.4, 5.6] # Vector{Float64}\n",
    "y = [0.4, 0.7, 0.9] # Vector{Float64}\n",
    "\n",
    "@time func(x,y);\n",
    "@time func(x,y);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a475ea",
   "metadata": {},
   "source": [
    "**First call:** compilation + running the code\n",
    "\n",
    "**Second call:** running the code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44115394",
   "metadata": {},
   "outputs": [],
   "source": [
    "@time func(x,y);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f74b788e",
   "metadata": {},
   "source": [
    "If one of the input types changes, Julia compiles a new specialization of the function!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21df8af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "typeof(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4add9224",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [1, 3, 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb28c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "typeof(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49854ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "@time func(x,y); # Vector{Int64}, Vector{Float64}\n",
    "@time func(x,y);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5c9af6e-a348-4871-aa89-53f310098baa",
   "metadata": {},
   "source": [
    "We now have two efficient native codes in the cache: one for all `Vector{Float64}` inputs and another one for `Vector{Int64}` as the first and `Vector{Float64}` as the second argument type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b8c246-cad7-4155-8fc5-899862be6cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "methods(func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8254a81-c2a3-4773-9c4f-7ed7ef160dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "using MethodAnalysis\n",
    "methodinstances(func)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20d5e0dc-d5ea-4e8c-b285-df29f3a37105",
   "metadata": {},
   "source": [
    "### Compilation pipeline\n",
    "\n",
    "<p><img src=\"./imgs/from_source_to_native.png\" alt=\"drawing\" width=\"800\"/></p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aac4fcc5-1839-4d3b-9243-886e3be7bd4e",
   "metadata": {},
   "source": [
    "### What makes Julia fast?\n",
    "\n",
    "(Successful) **Type inference** -> **Specialization** -> **Compilation**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75b6c894-0b8b-4457-aa21-c82389fa7671",
   "metadata": {},
   "source": [
    "## Introspection tools\n",
    "#### (*But I really want to see what happens!*)\n",
    "\n",
    "We can inspect the code at all transformation stages with a bunch of macros:\n",
    "\n",
    "<img src=\"./imgs/julia_introspection_macros.png\" width=350px>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa7a2b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "@macroexpand @time 3+3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a0d257",
   "metadata": {},
   "outputs": [],
   "source": [
    "@code_typed func(1.0,2.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "726260fe",
   "metadata": {},
   "source": [
    "From the types of the input arguments, Julia has figured out all the intermediate types and replaced the generic functions `*` and `+` by specific implementations (**static dispatch**). This crucial process is known as **type inference** and its success is the basis for a good specialization (i.e. performant native code as a result). It will concern us in much more detail tomorrow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a33e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "@code_llvm debuginfo=:none func(1.0,2.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dae32331",
   "metadata": {},
   "outputs": [],
   "source": [
    "@code_native debuginfo=:none func(1.0,2.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8b6ed56",
   "metadata": {},
   "source": [
    "Let's compare this to integer input.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff6e9653",
   "metadata": {},
   "outputs": [],
   "source": [
    "@code_native debuginfo=:none func(1,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dc2ea6d",
   "metadata": {},
   "source": [
    "### Recommendation: [Cthulhu.jl](https://github.com/JuliaDebug/Cthulhu.jl)\n",
    "While these introspection macros are great, I recommend to use `@descend` from the package [Cthulhu.jl](https://github.com/JuliaDebug/Cthulhu.jl) for real world code analysis.\n",
    "\n",
    "Essentially, Cthulhu is an **interactive**, more powerful generalization of the macros above.\n",
    "\n",
    "* Allows easy switching between code representations (syntax, typed, native, ...).\n",
    "* **Recursive application possible**(!) (i.e. introspecting a function that is called within a function within function ...).\n",
    "\n",
    "However, due to its interactivity, it doesn't work in Jupyter but **only works in the REPL** (→ exercise).\n",
    "\n",
    "<img src=\"imgs/cthulhu.png\" width=1000>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45872508",
   "metadata": {},
   "source": [
    "## How important is specialization?\n",
    "\n",
    "Let's try to estimate the performance gain by specialization.\n",
    "\n",
    "To prevent specialization, we deliberately throw away any useful type information and operate on a `Vector{Any}` that can literally store anything!\n",
    "\n",
    "(This is qualitatively comparable to what Python does.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "307bed1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "func(v) = 2*v[1] + v[2] # version of func that takes in a vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef3134a-027f-41c3-8d7f-11ffe11ca355",
   "metadata": {},
   "outputs": [],
   "source": [
    "rand(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c6ae38-70dd-42a3-a723-8b4eea2bacab",
   "metadata": {},
   "outputs": [],
   "source": [
    "Any[rand(), rand()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f49529fb",
   "metadata": {},
   "source": [
    "For benchmarking we will use `@btime` (or `@benchmark`) from [BenchmarkTools.jl](https://github.com/JuliaCI/BenchmarkTools.jl). This will take care of a couple of things for us:\n",
    "* Exclude first run.\n",
    "* Run the code multiple times (→ statistics).\n",
    "* Benchmark in a function (local scope).\n",
    "\n",
    "**General rule:** For proper benchmarking don't use `@time` but `@btime` and interpolate (`$`) global input arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7eadf19",
   "metadata": {},
   "outputs": [],
   "source": [
    "using BenchmarkTools\n",
    "\n",
    "v_typed = rand(2)\n",
    "v_any = Any[rand(), rand()]\n",
    "\n",
    "@btime func($v_typed);\n",
    "@btime func($v_any);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8283840e",
   "metadata": {},
   "outputs": [],
   "source": [
    "@benchmark func($v_any)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaaf2ba3-ac9b-4cdf-a5a0-17e748f1b4cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "@code_typed func(rand(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c70cd881-b2f0-4559-8015-5953c3fea257",
   "metadata": {},
   "outputs": [],
   "source": [
    "@code_typed func(Any[rand(), rand()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21663ee4-0c69-4d76-83de-cea6a56a791f",
   "metadata": {},
   "source": [
    "Note that in the latter case the generic functions `*` and `+` can not be replaced by specific variants due to lack of type information. This leads to inefficient **runtime dispatch**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc90c012",
   "metadata": {},
   "source": [
    "## Dispatch and specialization\n",
    "\n",
    "**Types drive both dispatch and specialization.**\n",
    "\n",
    "First, the most specific method is selected (dispatch), then it gets compiled to efficient native code (specialization)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "274d6488",
   "metadata": {},
   "outputs": [],
   "source": [
    "myabs(x::Real) = sign(x) * x\n",
    "myabs(z::Complex) = sqrt(real(z * conj(z)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9145b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "@code_native myabs(3.2 + 4.5im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a5fb226",
   "metadata": {},
   "outputs": [],
   "source": [
    "@code_native myabs(3 + 4im)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a90dbe57",
   "metadata": {},
   "source": [
    "## Are explicit type annotations necessary? (think C or Fortran)\n",
    "\n",
    "Note that Julia's type inference is powerful. Specifying types **is not** necessary for best performance!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea44980f",
   "metadata": {},
   "outputs": [],
   "source": [
    "function my_function(x)\n",
    "    y = rand()\n",
    "    z = rand()\n",
    "    x+y+z\n",
    "end\n",
    "\n",
    "function my_function_typed(x::Int)::Float64\n",
    "    y::Float64 = rand()\n",
    "    z::Float64 = rand()\n",
    "    x+y+z\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c53c0964",
   "metadata": {},
   "outputs": [],
   "source": [
    "@btime my_function(10);\n",
    "@btime my_function_typed(10);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dd19c86",
   "metadata": {},
   "source": [
    "Annotating types explicitly can serve a purpose.\n",
    "\n",
    "* Enforce conversions\n",
    "* Very rarely: help the compiler infer types in tricky situations\n",
    "\n",
    "However, more often than not it is an indication of suboptimal code design. (It also makes functions much less generic and reusable!)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef64848b-6e37-4cf8-a08d-29df33a930e3",
   "metadata": {},
   "source": [
    "## Note for heterogeneous HPC clusters\n",
    "\n",
    "By default, Julia produces native code for the CPU type it is running on. This means that it uses the [Instruction Set Architecture (ISA)](https://en.wikipedia.org/wiki/Instruction_set_architecture) of this CPU.\n",
    "\n",
    "This can lead to issues on heterogeneous clusters where different nodes have different CPU types. E.g. you precompile Julia packages on a login node with an Intel CPU but want to run the code on a compute node with AMD CPUs.\n",
    "\n",
    "**Solution: Multiversioning**\n",
    "\n",
    "```julia\n",
    "export JULIA_CPU_TARGET=\"generic;zen2,clone_all;skylake,clone_all\"\n",
    "```\n",
    "\n",
    "This will compile a generic (but slow) variant as well as efficient variants for AMD Zen2 and Intel Skylake CPUs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "271288b7",
   "metadata": {},
   "source": [
    "# Core messages of this Notebook\n",
    "\n",
    "* **A function is compiled when called for the first time** with a given set of argument types.\n",
    "* The are **multiple code transformation steps** which can be inspected through macros like `@code_warntype` or `@descend` from Cthulhu.jl.\n",
    "* What makes Julia fast? Successful **Type inference** → **Specialization** → **Compilation**.\n",
    "* Functions should almost always be benchmarked with **BenchmarkTools.jl's `@btime` and `@benchmark`** instead of `@time`.\n",
    "* In virtually all cases, **explicit type annotations are irrelevant for performance**."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.9.3",
   "language": "julia",
   "name": "julia-1.9"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.9.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
